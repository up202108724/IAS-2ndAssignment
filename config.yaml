# paths can be relative (to the parent dir of this file) or absolute
# paths should be constructed with (forward) slash '/', regardless of the operating system
# e.g. 'c:/Users/user/data' (Windows) or '/Users/user/data' (Unix)

general:
    # 'options.json' should be placed inside this directory 
    # This field will probably not need to be modified, you may leave it as it is
    rootdir: .

    # the parameter 'matildadir' is only needed if the ISA Engine is set to 'matlab'.
    # this is the directory with matilda source code (from InstanceSpace repo)
    # matildadir: ../InstanceSpace/

    # path to the dataset file (csv)
    # can be a relative path: ../datasets/data.csv
    datafile: wine_data.csv
    
    # type of problem: either classification or regression
    problem: classification

    # Parameter 'seed' is used to control reproducibiity
    # For reproducible results, set it to any integer value
    # For non-deterministic results, set it to the empty string: ""
    seed: 0

    # name of the target values' column in the dataset
    # leave this line commented out if using the last column as target column
    # target_col: class


# Feature selection
fs:
    enabled: True
    
    # The maximum number of features selected at the end
    max_n_features: 10
    
    # scoring method
    # Either 'NCA': Neighbourhood Components Analysis (recommended)
    # Or 'IT': Information Theoretic based
    method: NCA
    
    # naive variance filter; use it carefully!!
    # recommended: just remove features with var=0 (var_threshold=0)
    var_filter: True
    var_threshold: 0

    # correlation filter
    # removes redundant features greedly based on correlation coefficient
    # Warning: it is advisable that the previous step (variance filter) has been applied as well, 
    # to avoid presence of constant (zero variance) features.
    corr_filter: True
    corr_threshold: 0.95

# Hyper-parameter optimization (HPO)
hpo:
    enabled: True
    
    # Maximum number of evaluations (steps)
    evals: 10
    
    # Timeout for each fold (in seconds)
    timeout: 90


# ISA parameters
isa:
    # ISA Engine
    # One of: 'python' (recommended), 'matlab' or 'matlab_compiled'
    # Matlab engines will be removed in future versions
    engine: python

    # Threshold below which an instance is considered good
    # It should be either a float or 'auto' (recommended)
    # Works only for engine 'python'
    performance_threshold: auto
    
    # Adjust IS orientation, such that hard instances are placed in the upper left corner
    adjust_rotation: True

    # Instance hardness footprint parameters
    # easy instance if IH <= threshold
    ih_threshold: 0.4
    
    # ISA purity parameter (no need to change)
    ih_purity: 0.55


measures:
    # which measures to calculate
    list:
        # hardness measures for classification
        - kDN
        - DCP
        - TD_P
        - TD_U
        - CL
        - CLD
        - N1
        - N2
        - LSC
        - LSR
        - Harmfulness
        - Usefulness
        - F1
        # - F2
        # - F3

        # hardness measures for regression
        # - C4
        # - L1
        # - S1
        # - S2
        # - S3
        # - FO
        # - POT
        # - HB
        # - EDS
        # - EZR
        # - DS
        # - TD_P
        # - TD_U
        # - D
        # - CC


algos:
    # number of cross-validation folds to evaluate algorithm performance
    # suggestion: using 5 folds when hyper-parameter optimization is enabled, and 10 otherwise
    n_folds: 5
    
    # number of times the cross-validation is repeated. Instance metric is the mean over the iterations
    # suggestion: using 1 or 2 iters when hyper-parameter optimization is enabled, and 10 otherwise
    n_iter: 1

    # score metric used to evaluate instance performance
    # either 'logloss' (recommended) or 'brier' for classification
    # either 'normalized_absolute_error' (recommended) or 'normalized_squared_error' for regression
    metric: logloss

    # sampling strategy used for imbalanced datasets
    # during cross-validation, each training fold is resampled accordingly
    # possible strategies are: 'over', 'under', or 'no' (no attempt to balance)
    resampling: over

    # which algorithms (classifiers) to use
    pool:
        # classifiers
        - svc_linear
        - svc_rbf
        - random_forest
        - gradient_boosting
        - bagging
        - logistic_regression
        - mlp
        # - dummy

        # regressors
        # - ada_boost
        # - svr_linear
        # - svr_epsilon
        # - svr_nu
        # - decision_tree
        # - random_forest
        # - extra_tree
        # - gradient_boosting
        # - mlp
        # - bagging
        # - bayesian_ard
        # - kernel_ridge
        # - sgd
        # - passive_aggressive

    # fixed parameters for the classifiers
    # parameter 'random_state' controls the reproducibility
    # for different results, set it to None
    parameters:
        random_forest:
            n_jobs: -1
            
        bagging:
            n_jobs: -1
            
        # mlp:
        #    # "!!python/tuple" hack to pass a tuple (2,)
        #    hidden_layer_sizes: !!python/tuple [2,]
        #    max_iter: 1000

        # See: https://scikit-learn.org/0.16/modules/generated/sklearn.dummy.DummyClassifier.html
        dummy:
            strategy: prior
